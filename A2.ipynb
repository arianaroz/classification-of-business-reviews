{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Classification of Business Reviews\n",
    "\n",
    "Ariana Rozsnyoi 44616732"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reads business reviews which are part of the [Yelp Dataset stored in Kaggle](https://www.kaggle.com/yelp-dataset/yelp-dataset). The data are stored in a CSV file. The following code reads the CSV file and prints the contents of the first 5 records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>s2I_Ni76bjJNK9yG60iD-Q</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Had their chocolate almond croissant and it wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1  n6QzIUObkYshz4dz2QRJTw  bv2nCi5Qv5vroFiqKGopiw  VR6GpWIda3SfvPC-lg9H3w   \n",
       "2  MV3CcKScW05u5LVfF6ok0g  bv2nCi5Qv5vroFiqKGopiw  CKC0-MOWMqoeWf6s-szl8g   \n",
       "3  IXvOzsEMYtiJI0CARmj77Q  bv2nCi5Qv5vroFiqKGopiw  ACFtxLv8pGrrxMm6EgjreA   \n",
       "4  L_9BTb55X0GDtThi6GlZ6w  bv2nCi5Qv5vroFiqKGopiw  s2I_Ni76bjJNK9yG60iD-Q   \n",
       "\n",
       "   stars        date                                               text  \\\n",
       "0      5  2016-05-28  Super simple place but amazing nonetheless. It...   \n",
       "1      5  2016-05-28  Small unassuming place that changes their menu...   \n",
       "2      5  2016-05-28  Lester's is located in a beautiful neighborhoo...   \n",
       "3      4  2016-05-28  Love coming here. Yes the place always needs t...   \n",
       "4      4  2016-05-28  Had their chocolate almond croissant and it wa...   \n",
       "\n",
       "   useful  funny  cool  \n",
       "0       0      0     0  \n",
       "1       0      0     0  \n",
       "2       0      0     0  \n",
       "3       0      0     0  \n",
       "4       0      0     0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd_data = pd.read_csv('yelp_review.csv')\n",
    "pd_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data, we will only use the reviews and the star rating. The following code extracts this information and places it in a list of pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = list(zip(pd_data['text'], pd_data['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5261668"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Super simple place but amazing nonetheless. It's been around since the 30's and they still serve the same thing they started with: a bologna and salami sandwich with mustard. \\n\\nStaff was very helpful and friendly.\",\n",
       "  5),\n",
       " (\"Small unassuming place that changes their menu every so often. Cool decor and vibe inside their 30 seat restaurant. Call for a reservation. \\n\\nWe had their beef tartar and pork belly to start and a salmon dish and lamb meal for mains. Everything was incredible! I could go on at length about how all the listed ingredients really make their dishes amazing but honestly you just need to go. \\n\\nA bit outside of downtown montreal but take the metro out and it's less than a 10 minute walk from the station.\",\n",
       "  5),\n",
       " (\"Lester's is located in a beautiful neighborhood and has been there since 1951. They are known for smoked meat which most deli's have but their brisket sandwich is what I come to montreal for. They've got about 12 seats outside to go along with the inside. \\n\\nThe smoked meat is up there in quality and taste with Schwartz's and you'll find less tourists at Lester's as well.\",\n",
       "  5),\n",
       " (\"Love coming here. Yes the place always needs the floor swept but when you give out  peanuts in the shell how won't it always be a bit dirty. \\n\\nThe food speaks for itself, so good. Burgers are made to order and the meat is put on the grill when you order your sandwich. Getting the small burger just means 1 patty, the regular is a 2 patty burger which is twice the deliciousness. \\n\\nGetting the Cajun fries adds a bit of spice to them and whatever size you order they always throw more fries (a lot more fries) into the bag.\",\n",
       "  4),\n",
       " (\"Had their chocolate almond croissant and it was amazing! So light and buttery and oh my how chocolaty.\\n\\nIf you're looking for a light breakfast then head out here. Perfect spot for a coffee\\\\/latt√© before heading out to the old port\",\n",
       "  4)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check the distribution of star ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 731363, 2: 438161, 3: 615481, 4: 1223316, 5: 2253347})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter([rating for text, rating in all_data])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 5 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1782c4ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(1,6), [c[1], c[2], c[3], c[4], c[5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this assignment you will predict whether a particular review gives 5 stars or not.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is fairly large with more than 5 million samples. To speed up the computations for this assigmnent, we will use 500,000 samples for training,  10,000 for the dev-test set and 10,000 for the test set. To reduce any possible bias while partitioning the data set, we will first shuffle the data and then partition into training data, dev-test data, and test data using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1234)\n",
    "random.shuffle(all_data)\n",
    "train_data, devtest_data, test_data = all_data[:500000], all_data[500000:510000], all_data[510000:520000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (1 mark)\n",
    "The data are annotated with a star rating. In this assignment we will attempt to predict whether the review has 5 stars or not. In other words, we will use two categories: \"it does not have 5 stars\", and \"it has 5 stars\". According to these categories, check that the training data, devtest data and test data have the same proportions of the categories \"it does not have 5 stars\", and \"it has 5 stars\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "it has 5 stars:  214205\n",
      "it does not have 5 stars:  285795\n",
      "Proportion:  74.95%\n",
      "\n",
      "Devtest set\n",
      "it has 5 stars:  4275\n",
      "it does not have 5 stars:  5725\n",
      "Proportion:  74.67%\n",
      "\n",
      "Test set\n",
      "it has 5 stars:  4324\n",
      "it does not have 5 stars:  5676\n",
      "Proportion:  76.18%\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "print(\"Training Set\")\n",
    "fivestar1 = [s for s in train_data if s[1] ==5]\n",
    "fivecounter1 = collections.Counter(s[1] for s in fivestar1)\n",
    "\n",
    "notfive1= [s for s in train_data if s[1] != 5]\n",
    "counter1= collections.Counter(s[1] for s in notfive1)\n",
    "\n",
    "\n",
    "num1= sum(fivecounter1.values())\n",
    "num2= sum(counter1.values())\n",
    "\n",
    "print(\"it has 5 stars: \", num1)\n",
    "print(\"it does not have 5 stars: \", num2)\n",
    "\n",
    "print('Proportion: ', '{0:.2f}%'.format((num1 / num2 * 100)))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Devtest set\")\n",
    "fivestar2= [s for s in devtest_data if s[1] ==5]\n",
    "fivecounter2= collections.Counter(s[1] for s in fivestar2)\n",
    "\n",
    "notfive2= [s for s in devtest_data if s[1] != 5]\n",
    "counter2= collections.Counter(s[1] for s in notfive2)\n",
    "\n",
    "num3= sum(fivecounter2.values())\n",
    "num4= sum(counter2.values())\n",
    "\n",
    "print(\"it has 5 stars: \", num3)\n",
    "print(\"it does not have 5 stars: \", num4)\n",
    "\n",
    "print('Proportion: ', '{0:.2f}%'.format((num3 / num4 * 100)))\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Test set\")\n",
    "fivestar3 = [s for s in test_data if s[1] ==5]\n",
    "fivecounter3= collections.Counter(s[1] for s in fivestar3)\n",
    "\n",
    "notfive3= [s for s in test_data if s[1] != 5]\n",
    "counter3= collections.Counter(s[1] for s in notfive3)\n",
    "\n",
    "num5= sum(fivecounter3.values())\n",
    "num6= sum(counter3.values())\n",
    "\n",
    "print(\"it has 5 stars: \", num5)\n",
    "print(\"it does not have 5 stars: \", num6)\n",
    "\n",
    "print('Proportion: ', '{0:.2f}%'.format((num5/ num6 * 100)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 (2 marks)\n",
    "Use sklearn to generate the tf.idf matrix of the training set. With this matrix, train an sklearn Naive Bayes classifier using the training set and report the F1 scores of the training set, the devtest set, and the set set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_categories(text):\n",
    "    \"Split data into two classes\"\n",
    "    data = [(t,s) for (t,s) in text]\n",
    "    result = []\n",
    "    \n",
    "    for t,s in data:\n",
    "        if s==5:\n",
    "            result.append((t,1))\n",
    "        else:\n",
    "            result.append((t,0))\n",
    "    return result\n",
    "\n",
    "\n",
    "train_d = data_categories(train_data)\n",
    "devtest_d= data_categories(devtest_data)\n",
    "test_d = data_categories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(input='contents', stop_words='english', max_features=2000)\n",
    "tfidf = TfidfVectorizer(lowercase=True)\n",
    "\n",
    "tfidf_train = tfidf.fit_transform([x for x, y in train_d])\n",
    "tfidf_devtest = tfidf.transform([x for x, y in devtest_d])\n",
    "tfidf_test = tfidf.transform([x for x, y in test_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "sklearn_tfidfclassifier = MultinomialNB()\n",
    "sklearn_tfidfclassifier.fit(tfidf_train, [y for x, y in train_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of training set:  0.7295114545508621\n",
      "f1 score of devtest set:  0.6990077177508269\n",
      "f1 score of test set:  0.7070789259560618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score  \n",
    "\n",
    "print(\"f1 score of training set: \", f1_score([y for x, y in train_d], sklearn_tfidfclassifier.predict(tfidf_train)))\n",
    "print(\"f1 score of devtest set: \",f1_score([y for x, y in devtest_d], sklearn_tfidfclassifier.predict(tfidf_devtest)))\n",
    "print(\"f1 score of test set: \",f1_score([y for x, y in test_d], sklearn_tfidfclassifier.predict(tfidf_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score devtest set  0.7816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "print(\"Accuracy score devtest set \", accuracy_score([y for x, y in devtest_d], sklearn_tfidfclassifier.predict(tfidf_devtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (2 marks)\n",
    "Logistic regression normally produces better results than Naive Bayes but it takes longer time to train. Look at the [documentation of sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and train a logistic regression classifier using the same tfidf information as in exercise 2. Report the F1 scores of the training set, the devtest set, and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticregression = LogisticRegression()\n",
    "\n",
    "logistic_regression_train= logisticregression.fit(tfidf_train, [y for x, y in train_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of training set:  0.823389634728492\n",
      "f1 score of devtest set:  0.8146677566273502\n",
      "f1 score of test set:  0.807311320754717\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"f1 score of training set: \", f1_score([y for x, y in train_d], logistic_regression_train.predict(tfidf_train)))\n",
    "print(\"f1 score of devtest set: \",f1_score([y for x, y in devtest_d], logistic_regression_train.predict(tfidf_devtest)))\n",
    "print(\"f1 score of test set: \",f1_score([y for x, y in test_d], logistic_regression_train.predict(tfidf_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score devtest set:  0.850162\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score devtest set: \", accuracy_score([y for x, y in train_d], logisticregression.predict(tfidf_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (4 marks)\n",
    "Given the results obtained in the previous exercises, answer the following questions. You must justify all answers.\n",
    "\n",
    "#### 1. (1 mark) How much overfitting did you observe in the classifiers? \n",
    "\n",
    "  I did not observe overfitting in the classifiers as there is not a big difference in the F1 score outputs.\n",
    "\n",
    "\n",
    "#### 2. (1 mark) What would you do to reduce overfitting? \n",
    "   The test set and the training set results are only slighty different, so there is no need to reduce overfitting. From the given results it appears the model is not overfitting.\n",
    "    \n",
    "    \n",
    "    \n",
    "#### 3. (1 mark) Which classifier is better? \n",
    " The Logistic regression classifier is better than the Naive Bayes classifier as expected. It produces better F1 scores for the data sets.\n",
    "    \n",
    "#### 4. (1 mark) What can you conclude from the differences in the results between the dev-test set and the test set? \n",
    " There is only a slight difference in the results. This can be attributed to the size of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 (2 marks)\n",
    "Write code that counts the false positives and false negatives of the training set of each classifier. What can you conclude from such counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_classifier = sklearn_tfidfclassifier.predict(tfidf_train)\n",
    "\n",
    "logistic_classifier = logisticregression.predict(tfidf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_positives(result, category): \n",
    "    \"Return non-5 star reviews that were marked as 5 star\"\n",
    "    \n",
    "    return collections.Counter([category[i] for i in range(len(result)) if result[i] == 1 and \n",
    "           category[i] != 1])\n",
    "    \n",
    "def false_negatives(result, category):\n",
    "    \"Return 5 star reviews that were not marked as 5 star\"\n",
    "    \n",
    "    return collections.Counter([result[i] for i in range(len(result)) if result[i] != 1 \n",
    "            and category[i] == 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 79299})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives([s for t,s in train_d], tfidf_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 20742})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives([s for t,s in train_d], tfidf_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 39162})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives([s for t,s in train_d], logistic_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 35875})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives([s for t,s in train_d], logistic_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these counts we can deduce that the false positives on the tfidf classifier are much higher than the logistic regression classifier, indiciating the Logistic Regression classifier is doing a better job at prediciting reviews correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 (9 marks) - Improve the System and Final Analysis\n",
    "This exercise is open ended. Your goal is to perform a more detailed error analysis and identify ways to improve the classification of reviews **by adding or changing the features**. To obtain top marks in this part, your answer must address all of the following topics:\n",
    "\n",
    "1. An error analysis of the previous systems.\n",
    "2. Based on the error analysis, explain what sort of modifications you would want to implement, and justify why these would be useful modifications.\n",
    "3. Implementation of the improved classifier.\n",
    "4. Evaluation of the results and comparison with the previous classifiers. What system is best and why?\n",
    "5. Explain what further changes would possibly improve the classifier and why.\n",
    "\n",
    "** Note that, even if the new system might not obtain better results than the previous systems, you can obtain top marks if you perform a good error analysis of the initial systems and the final system and you give a sensible justification of the decisions that led you to implement the new system. Similarly, you may not obtain top marks if you present a system that improves on the results but you do not provide a good error analysis or you do not justify your choice of new system. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Error Analysis\n",
    "\n",
    "In order to analyse the errors of the previous systems we can look at the classification report and the Confusion Matrix. This will display the classification errors of our classifiers so we can further improve the system. As we are only classifying into two classes the two main errors are false positive and false negative. Generating the Confusion Matrix for each classifier we can visualize the difference in misclassification errors. The sklearn MultinomialNB classifier wrongly predicts 545 times more than the logisitc classifier. However, there are still many classification errors in both classifiers. These classification errors can be attributed to the types of words and language used in the reviews, making it difficult to differentiate between a 4 and a 5 star review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.92      0.83      5725\n",
      "          1       0.85      0.59      0.70      4275\n",
      "\n",
      "avg / total       0.79      0.78      0.77     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2536 1739]\n",
      " [ 445 5280]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"tfidf report \")\n",
    "print(classification_report([y for x, y in devtest_d], sklearn_tfidfclassifier.predict(tfidf_devtest)))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix([y for x, y in devtest_d], sklearn_tfidfclassifier.predict(tfidf_devtest), labels=[1,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.86      0.85      5725\n",
      "          1       0.81      0.79      0.80      4275\n",
      "\n",
      "avg / total       0.83      0.83      0.83     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[3386  889]\n",
      " [ 795 4930]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression report \")\n",
    "print(classification_report([y for x, y in devtest_d], logisticregression.predict(tfidf_devtest)))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix([y for x, y in devtest_d], logisticregression.predict(tfidf_devtest), labels=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Explanation of the Proposed New Classifier\n",
    "\n",
    "Adding an n-gram feature that looks at the combination of two or more words could improve classification prediction. \n",
    "There a various types of dependencies between words that contribute to text meaning (Ogada, Mwangi, & Cheruiyot 2015), which is not taken into consideration in the first classifiers. Words are treated as unigrams, independent from other words in the reviews. N-grams provide more meaning than a single word. For example the word \"good\" can be classified as either 4 or 5 stars, making it hard to predict correctly. Looking at the combination of word patterns such as \"very good\", \"pretty good\" and \"not good\" the classifier could better differentiate between each of the reviews and their associated ratings. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. Code of the Proposed New Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf3 = TfidfVectorizer(input='contents', ngram_range = (1,2), max_features= 2000,min_df=1)\n",
    "\n",
    "tfidf_train3 = tfidf3.fit_transform([x for x, y in train_d])\n",
    "tfidf_devtest3 = tfidf3.transform([x for x, y in devtest_d])\n",
    "tfidf_test3 = tfidf3.transform([x for x, y in test_d])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_tfidfclassifier3 = MultinomialNB()\n",
    "sklearn_tfidfclassifier3.fit(tfidf_train3, [y for x, y in train_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.8006\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy score: \", accuracy_score([y for x, y in devtest_d], sklearn_tfidfclassifier3.predict(tfidf_devtest3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Evaluation and Comparison\n",
    "In comparison to the previous classifer in exercise 2, the new classifier provides a slight improvement in results. The accuracy of the first classifier was 0.78 whereas the new classifier gives an accuracy score of 0.80. This can be attributed to the utilization of the n-grams feature providing the classifier with added sentiment. The new classifier is more accurate in predicting the distinction between a 5 star rating and a non 5 star rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Final Conclusions and Possible Improvements\n",
    "\n",
    "Overall, each classifier generates fairly good results in terms of prediciting whether a review is either 5 star or not. Adding an N-gram feature improved the accuracy results of the propsed classifier. Possible improvements or modifications could be to extend the sentiment analyiss to predict whether a review is 1,2,3,4 or 5 stars. This is more challenging than a two class prediction as now we have a multiclass.\n",
    "\n",
    "As stated by Wolpert (1996) there is no best classification algorithm. Depending on the data and problem some classifiers work better than others. For future improvements we could train an SVM model which usually performs well on large training sets and achieve good results, however require careful tuning and parameter selection (Caruana 2006). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References \n",
    "Caruana, R & Niculescu-Mizil, A (2006). An Empirical Comparison of Supervised Learning Algorithms, Department of Computer Science, Cornell University. \n",
    "\n",
    "Ogada, K,  Mwangi,W,  & Cheruiyot, W. (2015). N-gram based text categorization method for improved data mining. Vol 5. No 8. Journal of information engineering and applications. \n",
    "\n",
    "Wolpert, DH (1996). The Lack of A Priori Distinctions Between Learning Algorithms. Neural Computation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
